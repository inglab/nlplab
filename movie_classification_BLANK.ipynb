{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"movie_classification_BLANK.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"WxyikBfQJRAa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"e1892552-6ccd-48d1-c0db-6ebe3561c533"},"cell_type":"code","source":["# 데이터 체크 : movieidx \\t review \\t score\n","\n","rawtext= 'merged_comments.txt'\n","with open(rawtext, encoding= 'utf8')as f:\n","    for _ in range(10):\n","        print(f.readline().strip())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["45290\t크리스토퍼 놀란 에게 우리는 놀란 다\t10\n","45290\t인셉션 정말 흥미진진하게 봤었고 크리스토퍼 놀란 감독님 신작 인터스텔라도 이번주 일요일에 보러갑니다 완전 기대중\t10\n","45290\t놀란이면 무조건 봐야 된다 왜냐하면 모든 작품을 다 히트 쳤으니깐\t10\n","45290\t나는 감탄할 준비가 되어있다\t10\n","45290\t얘들아 오늘나오는거지 밤에 ㅋㅋ 오늘 보러가야겟다\t10\n","45290\t이제 죽어도 여한이 없다\t10\n","45290\t기대감에 잠도 안온다\t10\n","45290\t나랑 같이 봐 줄까 ㅎ\t10\n","45290\t우선 명감독들이 모였고 미국에서도 극찬을 받았더군\t10\n","45290\t드디어 내일 꼭본다\t10\n"],"name":"stdout"}]},{"metadata":{"id":"9MEcjur1JRAf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"71451569-75c7-41b1-829a-f55aadd2b469"},"cell_type":"code","source":["# 데이터 로드\n","\n","def load_reviews(fname, n_limit=-1): \n","    with open(fname, encoding='utf-8') as f:\n","        idxs = []\n","        scores = []\n","        texts = []\n","        \n","        for i, doc in enumerate(f):\n","            if n_limit > 0 and i >= n_limit:\n","                break\n","                \n","            try:\n","                idx, text, score = doc.strip().split('\\t')\n","                idxs.append(idx)\n","                texts.append(text.strip())\n","                scores.append(int(score))\n","                \n","            except Exception as e:\n","                print(e)\n","                continue\n","                \n","    return idxs, texts, scores\n","\n","idxs, texts, scores = load_reviews(rawtext)\n","print(len(idxs))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["294493\n"],"name":"stdout"}]},{"metadata":{"id":"4ZyCU0xyJRAi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"gAfeDv6KJRAk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"29e9aadd-e044-4cef-a3aa-d75144cdb014"},"cell_type":"code","source":["from collections import Counter\n","\n","word_count = Counter( [word for text in texts for word in text.strip().split()] )\n","\n","# 빈도수 상위 20개 단어 출력 / .itmes() method\n","\n","\n","# 1~n 번 이상 출현한 단어들의 수 출력\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('영화', 40000),\n"," ('정말', 18266),\n"," ('진짜', 14207),\n"," ('너무', 13397),\n"," ('이', 7893),\n"," ('영화를', 7006),\n"," ('그냥', 6844),\n"," ('더', 6560),\n"," ('최고의', 6394),\n"," ('보고', 5899),\n"," ('좀', 5725),\n"," ('수', 5671),\n"," ('영화가', 5588),\n"," ('최고', 5347),\n"," ('영화는', 5308),\n"," ('잘', 5039),\n"," ('꼭', 4944),\n"," ('ㅋㅋ', 4865),\n"," ('본', 4655),\n"," ('다', 4609)]\n","\n","limit = 1, the number of words : 400649\n","limit = 2, the number of words : 100035\n","limit = 3, the number of words : 61982\n","limit = 4, the number of words : 46182\n","limit = 5, the number of words : 37222\n","limit = 6, the number of words : 31295\n","limit = 7, the number of words : 27206\n"],"name":"stdout"}]},{"metadata":{"id":"8zr2UwoRJRAm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"7010870f-ca24-470c-c066-5e14d9a034ff"},"cell_type":"code","source":["# 인풋 텍스트에서 빈도 n 이상인 단어들만을 남기는 함수\n","def my_word_tokenizer(sentence_in_string):\n","    \n","    return sentence_tokenized # list\n","\n","print(texts[2])\n","print(my_word_tokenizer(texts[2]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["37222\n","놀란이면 무조건 봐야 된다 왜냐하면 모든 작품을 다 히트 쳤으니깐\n","['놀란이면', '무조건', '봐야', '된다', '왜냐하면', '모든', '작품을', '다', '히트']\n"],"name":"stdout"}]},{"metadata":{"id":"FyhvqTwIJRAr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"95d4f520-dbfe-4e94-db4a-70be8654bc43"},"cell_type":"code","source":["#영화 평점 별 리뷰 수\n","\n","for score, score_freq in sorted(Counter(scores).items()):\n","    print('score = %d: (%d, %.3f perc)' % (score, score_freq, 100*score_freq/len(scores)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["score = 1: (56122, 19.057 perc)\n","score = 2: (4725, 1.604 perc)\n","score = 3: (4547, 1.544 perc)\n","score = 4: (4062, 1.379 perc)\n","score = 5: (7697, 2.614 perc)\n","score = 6: (7588, 2.577 perc)\n","score = 7: (11338, 3.850 perc)\n","score = 8: (20311, 6.897 perc)\n","score = 9: (25528, 8.668 perc)\n","score = 10: (152575, 51.809 perc)\n"],"name":"stdout"}]},{"metadata":{"id":"iQRsEYbMJRAt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"0f6a1fd6-7363-4ad0-8b4d-c1a4c60c7f40"},"cell_type":"code","source":["# 1~3 점은 -1\n","# 9,10점은 1\n","# 나머지는 사용하지 않음\n","\n","train_texts = []\n","train_label = []\n","\n","for review, score in zip(texts, scores):\n","    if 3 < score < 9:\n","        continue\n","    tokenized_review = my_word_tokenizer(review)\n","    if not tokenized_review:\n","        continue\n","  \n","    train_texts.append(tokenized_review)\n","    train_label.append(1 if score >= 9 else -1)\n","\n","print('train data: %d --> %d' % (len(texts), len(train_texts)))\n","for label, label_freq in Counter(train_label).items():\n","    print('label = %d: (%d, %.3f perc)' % (label, label_freq, 100*label_freq/len(train_label)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train data: 294493 --> 226572\n","label = 1: (166225, 73.365 perc)\n","label = -1: (60347, 26.635 perc)\n"],"name":"stdout"}]},{"metadata":{"id":"ojS5O6kQJRAw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"SmWdZuIqJRAy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"4b0d979f-7965-4f69-f5e8-08e3b987d823"},"cell_type":"code","source":["# 단어의 빈도수로 벡터화\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","\n","vectorizer= CountVectorizer(\n","    tokenizer = lambda x:x , lowercase = False, \n","  \n","    )\n","\n","train_x= vectorizer.fit_transform(train_texts) # train_texts가 string 이라면 tokenizer 설정 필요 x\n","\n","\n","print(type(train_x) ) \n","train_x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'scipy.sparse.csr.csr_matrix'>\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<226572x37134 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 1283074 stored elements in Compressed Sparse Row format>"]},"metadata":{"tags":[]},"execution_count":106}]},{"metadata":{"id":"daZqdEcbJRA2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"1fbe432d-a311-4a31-a8de-945e3d4a85c5"},"cell_type":"code","source":["# 특정 단어에 해당하는 인덱스 알아보기\n","\n","vocab2int = vectorizer.vocabulary_ #dictionary, {word: index} 형태\n","print(vocab2int['영화'])\n","\n","int2vocab = [word for word,index in sorted # 단어를 철자순으로 정렬한 list\n","             (vocab2int.items(), key=lambda x:x[1])] \n","\n","\n","print(int2vocab[24175]) # 위에서 출력된 수 입력\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["24175\n","영화\n"],"name":"stdout"}]},{"metadata":{"id":"XtMyRhZYJRA4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"74dc0aa8-a584-4807-bb4a-a763dc3d52e5"},"cell_type":"code","source":["# logistic_regression train\n","from sklearn.linear_model import LogisticRegression\n","\n","\n","logistic = LogisticRegression()\n","logistic.fit(train_x, train_label)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n","          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n","          verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":109}]},{"metadata":{"id":"5sDBsP9xJRA8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"4363ef51-561d-4b5e-966b-0d893cdc5cdb"},"cell_type":"code","source":["# n 번째 리뷰들을 골라 predict 해보기\n","\n","for idx in [14,100,1000,199999,200006]: # any number\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["text: ['재미없다', '이상', '10자']\n","\n","predicted class prob: (negative= 0.754, positive= 0.246\n","predicted class = negative\n","actual class = negative\n","\n","--------------------------------------------------\n","\n","text: ['정말정말', '대단합니다']\n","\n","predicted class prob: (negative= 0.048, positive= 0.952\n","predicted class = positive\n","actual class = positive\n","\n","--------------------------------------------------\n","\n","text: ['관람객진짜', '인생영화다', '꼭', '봐야하는', '영화']\n","\n","predicted class prob: (negative= 0.004, positive= 0.996\n","predicted class = positive\n","actual class = positive\n","\n","--------------------------------------------------\n","\n","text: ['빵점주고싶다']\n","\n","predicted class prob: (negative= 0.660, positive= 0.340\n","predicted class = negative\n","actual class = negative\n","\n","--------------------------------------------------\n","\n","text: ['나도', '최악에', '한표', 'ㅋㅋ']\n","\n","predicted class prob: (negative= 0.921, positive= 0.079\n","predicted class = negative\n","actual class = negative\n","\n","--------------------------------------------------\n","\n"],"name":"stdout"}]},{"metadata":{"id":"YXk09OH5JRA_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"e8f7d580-8543-45b8-fb83-be28bcadd065"},"cell_type":"code","source":["#coefficients 살펴보기\n","\n","# 긍정리뷰로 예측하는데 영향을 미친 단어들 상위 10\n","coefficients = logistic.coef_.tolist()\n","sorted_coefficients = sorted(enumerate(coefficients[0]), \n","                             key=lambda x:x[1], reverse=True)\n","\n","for index, coef in sorted_coefficients[:10]:\n","    print('%s (%.3f)' % (int2vocab[index], coef))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["알이즈웰 (4.316)\n","최고입니다 (3.503)\n","관람객재밌어요 (3.227)\n","기대됩니다 (3.199)\n","10점준다 (3.118)\n","좋았어요 (3.089)\n","웰 (2.987)\n","재미있었습니다 (2.978)\n","꿀잼 (2.934)\n","인생영화 (2.934)\n"],"name":"stdout"}]},{"metadata":{"id":"c63F5f3TJRBB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"5bfdc586-d77f-4669-d283-2063678b96a6"},"cell_type":"code","source":["# 부정리뷰로 예측하는데 영향을 미친 단어들 상위 10\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0점은 (-4.261)\n","최악 (-4.248)\n","최악의 (-4.187)\n","0점이 (-3.892)\n","1점준다 (-3.749)\n","돈아깝다 (-3.736)\n","쓰레기영화 (-3.608)\n","1점대 (-3.566)\n","노잼 (-3.559)\n","최악의영화 (-3.474)\n"],"name":"stdout"}]},{"metadata":{"id":"w4LBNl6-8Ww5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 5-fold-cross-validation 으로 accuracy, precision, recall 등 구하기"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gSeIOXGa8RNh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Train, Test set을 나누어  성능 측정 (accuracy, recall, precision, F1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zd1Hw2xV8dzB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 다른 머신러닝 알고리즘 사용해서 성능 비교 "],"execution_count":0,"outputs":[]},{"metadata":{"id":"rtCntV_tJRBE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# from konlpy.tag import Twitter # hannanum etc..\n","# from sklearn.linear_model import LogisticRegression\n","# from sklearn.svm import SVC\n","# from sklearn.model_selection import cross_val_predict, train_test_split\n","# from sklearn.metrics import confusion_matrix\n","\n","\n","# konlpy를 이용한 품사 분석\n","\n","# 빈도수, 품사 등을 이용한 stop words 처리\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DO5J6zxhJRBH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"bFPbF9RxJRBJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"N2o2LvLBJRBL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"UDCMJmhrJRBM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}